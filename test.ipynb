{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c808ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\luizc\\anaconda3\\lib\\site-packages (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\luizc\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\luizc\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\luizc\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\luizc\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\luizc\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\luizc\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\luizc\\anaconda3\\lib\\site-packages (4.8.0.74)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.9.0.80-cp37-abi3-win_amd64.whl (38.6 MB)\n",
      "     --------------------------------------- 38.6/38.6 MB 23.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\luizc\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Installing collected packages: opencv-python\n",
      "  Attempting uninstall: opencv-python\n",
      "    Found existing installation: opencv-python 4.8.0.74\n",
      "    Uninstalling opencv-python-4.8.0.74:\n",
      "      Successfully uninstalled opencv-python-4.8.0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\luizc\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\luizc\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\luizc\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\luizc\\anaconda3\\lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\luizc\\\\anaconda3\\\\Lib\\\\site-packages\\\\~-2\\\\cv2.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\luizc\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\luizc\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\luizc\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade numpy\n",
    "!pip install --upgrade opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d15226f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0x10 but this version of numpy is 0xe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0x10 but this version of numpy is 0xe"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "initialization of _pywrap_checkpoint_reader raised unreported exception",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1192\\4136337184.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhog\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexposure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvgg16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;34m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__internal__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\__internal__\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;34m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\__internal__\\backend\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;34m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_initialize_variables\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minitialize_variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrack_variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \"\"\"\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\applications\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvnext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConvNeXtBase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvnext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConvNeXtLarge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvnext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConvNeXtSmall\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\applications\\convnext.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[0m_tf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__internal__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__operators__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maudio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0meager_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\distribute\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minterim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmulti_process_runner\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\distribute\\combinations\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcombinations\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0menv\u001b[0m \u001b[1;31m# line: 456\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcombinations\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgenerate\u001b[0m \u001b[1;31m# line: 365\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcombinations\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0min_main_process\u001b[0m \u001b[1;31m# line: 418\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\combinations.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcollective_all_reduce_strategy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmulti_process_runner\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\collective_all_reduce_strategy.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow_server_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcollective_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_device_ops\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcross_device_ops_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_device_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdevice_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\cross_device_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdevice_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcollective_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_device_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdevice_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\cross_device_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcollective_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mvalue_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackprop_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\values.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstruct_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdevice_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpacked_distributed_variable\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpacked\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mreduce_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mag_ctx\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mautograph_ctx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimpl\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapi\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdataset_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcollective_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdevice_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdataset_autograph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdebug_mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptions\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moptions_lib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstructured_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnested_structure_coder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrackable\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaver\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseSaverBuilder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeprecation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_saved_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrackable\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbase\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpy_checkpoint_reader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msaveable_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\py_checkpoint_reader.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pywrap_checkpoint_reader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCheckpointReader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_export\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf_export\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSystemError\u001b[0m: initialization of _pywrap_checkpoint_reader raised unreported exception"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import mysql.connector\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "from keras.applications import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Load pre-trained VGG16 model\n",
    "vgg16_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Function to extract LBP features\n",
    "def extract_lbp_features(image):\n",
    "    gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    lbp = cv2.LBP_create()\n",
    "    lbp_img = lbp.compute(gray_img)[0]  # Compute LBP image\n",
    "    hist, _ = np.histogram(lbp_img.ravel(), bins=np.arange(0, 256), range=(0, 256))\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + 1e-7)  # Normalize histogram\n",
    "    return hist\n",
    "\n",
    "# Function to extract combined features\n",
    "def extract_combined_features(image):\n",
    "    # Resize image while preserving aspect ratio\n",
    "    resized_img = cv2.resize(image, (128, 64))  # Adjust size as needed\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Extract HOG features\n",
    "    hog_features, _ = hog(gray_img, orientations=9, pixels_per_cell=(8, 8),\n",
    "                          cells_per_block=(2, 2), block_norm='L2-Hys',\n",
    "                          visualize=True, transform_sqrt=True)\n",
    "    \n",
    "    # Enhance HOG image for visualization\n",
    "    hog_img = exposure.rescale_intensity(hog_img, in_range=(0, 10))\n",
    "\n",
    "    # Extract color histogram features\n",
    "    color_features = cv2.calcHist([resized_img], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256]).flatten()\n",
    "\n",
    "    # Extract LBP features\n",
    "    lbp_features = extract_lbp_features(image)\n",
    "    \n",
    "    # Preprocess image for VGG16\n",
    "    img = cv2.resize(image, (224, 224))\n",
    "    img_array = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    \n",
    "    # Extract VGG16 features\n",
    "    vgg16_features = vgg16_model.predict(img_array).flatten()\n",
    "    \n",
    "    # Combine all features\n",
    "    combined_features = np.hstack((hog_features, color_features, lbp_features, vgg16_features))\n",
    "    \n",
    "    return combined_features\n",
    "\n",
    "# Function to load and extract features from images fetched from MySQL\n",
    "def load_and_extract_features_from_mysql(cursor, feature_extractor):\n",
    "    cursor.execute(\"SELECT image_path, building_name, location FROM images JOIN buildings ON images.building_id = buildings.building_id\")\n",
    "    features = []\n",
    "    labels = []\n",
    "    locations = []\n",
    "    for image_path, building_name, location in cursor:\n",
    "        img = cv2.imread(image_path)\n",
    "        img_features = feature_extractor(img)\n",
    "        features.append(img_features)\n",
    "        labels.append(building_name)\n",
    "        locations.append(location)\n",
    "    return features, labels, locations\n",
    "\n",
    "# MySQL info\n",
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'user': 'root',\n",
    "    'password': 'Luiz2001!',\n",
    "    'database': 'campus_tour',\n",
    "}\n",
    "\n",
    "# Open connection to DB\n",
    "conn = mysql.connector.connect(**db_config)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Load and extract features using the combined feature extractor\n",
    "X_features, y_labels, locations_train = load_and_extract_features_from_mysql(cursor, extract_combined_features)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(X_features)\n",
    "y = np.array(y_labels)\n",
    "\n",
    "# Shuffle the data\n",
    "X, y, locations_train = shuffle(X, y, locations_train, random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test, locations_train, _ = train_test_split(X, y, locations_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels for the testing data\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Close DB connection\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "# Function for data augmentation\n",
    "def augment_data(images):\n",
    "    augmented_images = []\n",
    "    for img in images:\n",
    "        # Apply transformations to the image (e.g., rotation, flipping, scaling)\n",
    "        augmented_img = img  # Placeholder for transformation code\n",
    "        augmented_images.append(augmented_img)\n",
    "    return augmented_images\n",
    "\n",
    "# Augment data\n",
    "X_train_augmented = augment_data(X_train)\n",
    "y_train_augmented = np.tile(y_train,  # Keep the same labels for augmented data\n",
    "                            len(X_train_augmented) // len(X_train))\n",
    "\n",
    "# Combine original and augmented data\n",
    "X_combined = np.concatenate((X_train, X_train_augmented))\n",
    "y_combined = np.concatenate((y_train, y_train_augmented))\n",
    "\n",
    "# Perform cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "for train_index, test_index in kf.split(X_combined):\n",
    "    X_train_fold, X_test_fold = X_combined[train_index], X_combined[test_index]\n",
    "    y_train_fold, y_test_fold = y_combined[train_index], y_combined[test_index]\n",
    "    \n",
    "    # Train Random Forest classifier\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_classifier.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Predict labels for the testing data\n",
    "    y_pred_fold = rf_classifier.predict(X_test_fold)\n",
    "    \n",
    "    # Calculate accuracy for this fold\n",
    "    accuracy_fold = accuracy_score(y_test_fold, y_pred_fold)\n",
    "    accuracies.append(accuracy_fold)\n",
    "\n",
    "# Calculate mean accuracy across folds\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "print(\"Mean Cross-Validated Accuracy:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "750fe6e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2608695652173913\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           Aiken       0.00      0.00      0.00         2\n",
      "             CCM       0.12      0.50      0.19         4\n",
      "     Durick Hall       0.25      0.50      0.33         2\n",
      "     Finney Quad       0.00      0.00      0.00         1\n",
      "     Foster Hall       0.00      0.00      0.00         1\n",
      "    Garden House       0.00      0.00      0.00         3\n",
      " Hauke Courtyard       0.00      0.00      0.00         1\n",
      "             IDX       0.00      0.00      0.00         2\n",
      "      Joyce Hall       0.00      0.00      0.00         1\n",
      "    Juniper Bike       0.00      0.00      0.00         1\n",
      "Metz Studio Barn       0.00      0.00      0.00         2\n",
      "   Miller Center       0.00      0.00      0.00         1\n",
      "      Perry Hall       0.50      0.40      0.44         5\n",
      "    Rowell Annex       0.00      0.00      0.00         1\n",
      "      SD Ireland       0.00      0.00      0.00         7\n",
      "      Skiff Hall       0.33      0.88      0.48         8\n",
      "       West Hall       0.00      0.00      0.00         2\n",
      "       Wick Hall       0.00      0.00      0.00         2\n",
      "\n",
      "        accuracy                           0.26        46\n",
      "       macro avg       0.07      0.13      0.08        46\n",
      "    weighted avg       0.13      0.26      0.16        46\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0]\n",
      " [0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 2 0 0 2 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 4 0 0 0 0 0 0 0 0 0 0 2 0 0 1 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 7 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luizc\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luizc\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luizc\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validated Accuracy: 0.8944444444444445\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import mysql.connector\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Function to extract combined HOG and color features\n",
    "def extract_combined_features(image):\n",
    "    # Resize image while preserving aspect ratio\n",
    "    resized_img = cv2.resize(image, (128, 64))  # Adjust size as needed\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Extract HOG features\n",
    "    hog_features, hog_img = hog(gray_img, orientations=9, pixels_per_cell=(8, 8),\n",
    "                                cells_per_block=(2, 2), block_norm='L2-Hys',\n",
    "                                visualize=True, transform_sqrt=True)\n",
    "    \n",
    "    # Enhance HOG image for visualization\n",
    "    hog_img = exposure.rescale_intensity(hog_img, in_range=(0, 10))\n",
    "\n",
    "    # Extract color histogram features\n",
    "    color_features = cv2.calcHist([resized_img], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256]).flatten()\n",
    "    \n",
    "    # Combine HOG and color features\n",
    "    combined_features = np.hstack((hog_features, color_features))\n",
    "    \n",
    "    return combined_features\n",
    "\n",
    "# Function to load and extract features from images fetched from MySQL\n",
    "def load_and_extract_features_from_mysql(cursor, feature_extractor):\n",
    "    cursor.execute(\"SELECT image_path, building_name, location FROM images JOIN buildings ON images.building_id = buildings.building_id\")\n",
    "    features = []\n",
    "    labels = []\n",
    "    locations = []\n",
    "    for image_path, building_name, location in cursor:\n",
    "        img = cv2.imread(image_path)\n",
    "        img_features = feature_extractor(img)\n",
    "        features.append(img_features)\n",
    "        labels.append(building_name)\n",
    "        locations.append(location)\n",
    "    return features, labels, locations\n",
    "\n",
    "# MySQL info\n",
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'user': 'root',\n",
    "    'password': 'Luiz2001!',\n",
    "    'database': 'campus_tour',\n",
    "}\n",
    "\n",
    "# Open connection to DB\n",
    "conn = mysql.connector.connect(**db_config)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Load and extract features using the combined feature extractor\n",
    "X_features, y_labels, locations_train = load_and_extract_features_from_mysql(cursor, extract_combined_features)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(X_features)\n",
    "y = np.array(y_labels)\n",
    "\n",
    "# Shuffle the data\n",
    "X, y, locations_train = shuffle(X, y, locations_train, random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test, locations_train, _ = train_test_split(X, y, locations_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels for the testing data\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Close DB connection\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "# Function for data augmentation\n",
    "def augment_data(images):\n",
    "    augmented_images = []\n",
    "    for img in images:\n",
    "        # Apply transformations to the image (e.g., rotation, flipping, scaling)\n",
    "        augmented_img = img  # Placeholder for transformation code\n",
    "        augmented_images.append(augmented_img)\n",
    "    return augmented_images\n",
    "\n",
    "# Augment data\n",
    "X_train_augmented = augment_data(X_train)\n",
    "y_train_augmented = np.tile(y_train,  # Keep the same labels for augmented data\n",
    "                            len(X_train_augmented) // len(X_train))\n",
    "\n",
    "# Combine original and augmented data\n",
    "X_combined = np.concatenate((X_train, X_train_augmented))\n",
    "y_combined = np.concatenate((y_train, y_train_augmented))\n",
    "\n",
    "# Perform cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "for train_index, test_index in kf.split(X_combined):\n",
    "    X_train_fold, X_test_fold = X_combined[train_index], X_combined[test_index]\n",
    "    y_train_fold, y_test_fold = y_combined[train_index], y_combined[test_index]\n",
    "    \n",
    "    # Train Random Forest classifier\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_classifier.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Predict labels for the testing data\n",
    "    y_pred_fold = rf_classifier.predict(X_test_fold)\n",
    "    \n",
    "    # Calculate accuracy for this fold\n",
    "    accuracy_fold = accuracy_score(y_test_fold, y_pred_fold)\n",
    "    accuracies.append(accuracy_fold)\n",
    "\n",
    "# Calculate mean accuracy across folds\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "print(\"Mean Cross-Validated Accuracy:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "294f8187",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validated Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Function for data augmentation\n",
    "def augment_data(images):\n",
    "    augmented_images = []\n",
    "    for img in images:\n",
    "        # Apply transformations to the image (e.g., rotation, flipping, scaling)\n",
    "        augmented_img = img  # Placeholder for transformation code\n",
    "        augmented_images.append(augmented_img)\n",
    "    return augmented_images\n",
    "\n",
    "# Augment data\n",
    "X_train_augmented = augment_data(X_train)\n",
    "y_train_augmented = np.tile(y_train,  # Keep the same labels for augmented data\n",
    "                            len(X_train_augmented) // len(X_train))\n",
    "\n",
    "# Combine original and augmented data\n",
    "X_combined = np.concatenate((X_train, X_train_augmented))\n",
    "y_combined = np.concatenate((y_train, y_train_augmented))\n",
    "\n",
    "# Perform cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "for train_index, test_index in kf.split(X_combined):\n",
    "    X_train_fold, X_test_fold = X_combined[train_index], X_combined[test_index]\n",
    "    y_train_fold, y_test_fold = y_combined[train_index], y_combined[test_index]\n",
    "    \n",
    "    # Train Random Forest classifier\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_classifier.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Predict labels for the testing data\n",
    "    y_pred_fold = rf_classifier.predict(X_test_fold)\n",
    "    \n",
    "    # Calculate accuracy for this fold\n",
    "    accuracy_fold = accuracy_score(y_test_fold, y_pred_fold)\n",
    "    accuracies.append(accuracy_fold)\n",
    "\n",
    "# Calculate mean accuracy across folds\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "print(\"Mean Cross-Validated Accuracy:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a307193b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80fcbecf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luizc\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luizc\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luizc\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luizc\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luizc\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luizc\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validated Accuracy: 0.3983574879227053\n",
      "Mean Cross-Validated Precision: 0.3193917367487161\n",
      "Mean Cross-Validated Recall: 0.3983574879227053\n",
      "Mean Cross-Validated F1-score: 0.3095960215475932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luizc\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Initialize lists to store evaluation metrics for each fold\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "# Perform cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    X_train_fold, X_test_fold = X[train_index], X[test_index]\n",
    "    y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "    \n",
    "    # Augment data for this fold\n",
    "    X_train_fold_augmented = augment_data(X_train_fold)\n",
    "    y_train_fold_augmented = np.tile(y_train_fold, len(X_train_fold_augmented) // len(X_train_fold))\n",
    "    \n",
    "    # Combine original and augmented data\n",
    "    X_train_combined = np.concatenate((X_train_fold, X_train_fold_augmented))\n",
    "    y_train_combined = np.concatenate((y_train_fold, y_train_fold_augmented))\n",
    "    \n",
    "    # Train Random Forest classifier\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_classifier.fit(X_train_combined, y_train_combined)\n",
    "    \n",
    "    # Predict labels for the testing data\n",
    "    y_pred_fold = rf_classifier.predict(X_test_fold)\n",
    "    \n",
    "    # Calculate evaluation metrics for this fold\n",
    "    accuracy_fold = accuracy_score(y_test_fold, y_pred_fold)\n",
    "    precision_fold = precision_score(y_test_fold, y_pred_fold, average='weighted')\n",
    "    recall_fold = recall_score(y_test_fold, y_pred_fold, average='weighted')\n",
    "    f1_fold = f1_score(y_test_fold, y_pred_fold, average='weighted')\n",
    "    \n",
    "    # Append scores to lists\n",
    "    accuracy_scores.append(accuracy_fold)\n",
    "    precision_scores.append(precision_fold)\n",
    "    recall_scores.append(recall_fold)\n",
    "    f1_scores.append(f1_fold)\n",
    "\n",
    "# Calculate mean scores across folds\n",
    "mean_accuracy = np.mean(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores)\n",
    "mean_recall = np.mean(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "\n",
    "# Print the mean scores\n",
    "print(\"Mean Cross-Validated Accuracy:\", mean_accuracy)\n",
    "print(\"Mean Cross-Validated Precision:\", mean_precision)\n",
    "print(\"Mean Cross-Validated Recall:\", mean_recall)\n",
    "print(\"Mean Cross-Validated F1-score:\", mean_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c15e1b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validated Accuracy: 0.2777777777777778\n",
      "Image: Aiken_1_image.jpg, Predicted Label: CCM\n",
      "Image: CCM_1_image.jpg, Predicted Label: Durick Hall\n",
      "Image: Joyce_1_image.jpg, Predicted Label: Samuel De Champlain\n",
      "Image: perry_4_image.jpg, Predicted Label: Perry Hall\n",
      "Image: SD IREland_1_image.jpg, Predicted Label: Perry Hall\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Function for data augmentation\n",
    "def augment_data(images, labels, max_samples_per_class=4):\n",
    "    augmented_images = []\n",
    "    augmented_labels = []\n",
    "    samples_per_class = {}  # Dictionary to keep track of samples per class\n",
    "    \n",
    "    for img, label in zip(images, labels):\n",
    "        # Check if the current class has reached the maximum allowed samples\n",
    "        if label not in samples_per_class:\n",
    "            samples_per_class[label] = 1\n",
    "        else:\n",
    "            if samples_per_class[label] >= max_samples_per_class:\n",
    "                continue  # Skip augmentation for this sample\n",
    "        \n",
    "        # Apply transformations to the image (e.g., rotation, flipping, scaling)\n",
    "        augmented_img = img  # Placeholder for transformation code\n",
    "        augmented_images.append(augmented_img)\n",
    "        augmented_labels.append(label)\n",
    "        \n",
    "        # Increment the count of samples for the current class\n",
    "        samples_per_class[label] += 1\n",
    "        \n",
    "    return augmented_images, augmented_labels\n",
    "\n",
    "# Function to load and preprocess images from a directory\n",
    "def load_and_preprocess_images_from_directory(directory):\n",
    "    images = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            img_path = os.path.join(directory, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            img_features = extract_combined_features(img)  # Assuming you have a function for feature extraction\n",
    "            images.append((filename, img_features))\n",
    "    return images\n",
    "\n",
    "# Directory containing the downloaded images\n",
    "test_images_directory = \"C:/Users/luizc/Capstone/test_images/\"\n",
    "\n",
    "# Load and preprocess test images\n",
    "test_images = load_and_preprocess_images_from_directory(test_images_directory)\n",
    "\n",
    "# Perform cross-validation\n",
    "\n",
    "# Assuming X_train and y_train are defined\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]\n",
    "    y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
    "    \n",
    "    # Augment data with a maximum of 4 samples per class\n",
    "    X_train_augmented, y_train_augmented = augment_data(X_train_fold, y_train_fold, max_samples_per_class=4)\n",
    "    \n",
    "    # Combine original and augmented data\n",
    "    X_combined = np.concatenate((X_train_fold, X_train_augmented))\n",
    "    y_combined = np.concatenate((y_train_fold, y_train_augmented))\n",
    "    \n",
    "    # Train Random Forest classifier\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_classifier.fit(X_combined, y_combined)\n",
    "    \n",
    "    # Predict labels for the testing data\n",
    "    y_pred_fold = rf_classifier.predict(X_test_fold)\n",
    "    \n",
    "    # Calculate accuracy for this fold\n",
    "    accuracy_fold = accuracy_score(y_test_fold, y_pred_fold)\n",
    "    accuracies.append(accuracy_fold)\n",
    "\n",
    "# Calculate mean accuracy across folds\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "print(\"Mean Cross-Validated Accuracy:\", mean_accuracy)\n",
    "\n",
    "# Predict labels for the test images\n",
    "predicted_labels = []\n",
    "for filename, img_features in test_images:\n",
    "    predicted_label = rf_classifier.predict([img_features])[0]\n",
    "    predicted_labels.append((filename, predicted_label))\n",
    "\n",
    "# Write out the predicted labels for each image\n",
    "for filename, predicted_label in predicted_labels:\n",
    "    print(f\"Image: {filename}, Predicted Label: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75858d25",
   "metadata": {},
   "source": [
    "# 4 samples compiled with location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2fd2b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c9baaab",
   "metadata": {},
   "source": [
    "# Dont touch just in case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf25a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6543b1e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a1c418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04ea251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e99404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daa05b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.36363636363636365\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "              Aiken       0.00      0.00      0.00         1\n",
      "                CCM       0.25      0.83      0.38         6\n",
      "        Durick Hall       0.50      0.33      0.40         3\n",
      "       Freeman Hall       0.00      0.00      0.00         2\n",
      "       Garden House       0.00      0.00      0.00         1\n",
      "      Health Center       0.00      0.00      0.00         2\n",
      "                IDX       0.00      0.00      0.00         4\n",
      "         Joyce Hall       0.00      0.00      0.00         1\n",
      "       Juniper Bike       0.00      0.00      0.00         1\n",
      "   Metz Studio Barn       0.00      0.00      0.00         1\n",
      "         Perry Hall       0.60      1.00      0.75         3\n",
      "       Rowell Annex       0.00      0.00      0.00         1\n",
      "         SD Ireland       0.00      0.00      0.00         5\n",
      "Samuel De Champlain       0.00      0.00      0.00         2\n",
      "         Skiff Hall       0.44      0.70      0.54        10\n",
      "          West Hall       0.00      0.00      0.00         1\n",
      "\n",
      "           accuracy                           0.36        44\n",
      "          macro avg       0.11      0.18      0.13        44\n",
      "       weighted avg       0.21      0.36      0.25        44\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 5 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0 0 0 0 0 0 0 0 0 2 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 3 0 0 0 0 0 0 0 0 0 0 0 0 2 0]\n",
      " [0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 3 0 0 0 0 0 0 0 0 0 0 0 0 7 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luizc\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luizc\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luizc\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from skimage.feature import hog, daisy\n",
    "from skimage import io\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Function to extract HOG features\n",
    "def extract_hog_features(image):\n",
    "    resized_img = cv2.resize(image, (64, 32))\n",
    "    gray_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2GRAY)\n",
    "    hog_features = hog(gray_img, block_norm='L2-Hys', pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=False)\n",
    "    return hog_features\n",
    "\n",
    "# Function to extract DAISY features\n",
    "def extract_daisy_features(image):\n",
    "    resized_img = cv2.resize(image, (64, 32))\n",
    "    gray_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2GRAY)\n",
    "    daisy_features = daisy(gray_img, step=8, radius=8, rings=2, histograms=6, visualize=False)\n",
    "    return daisy_features.flatten()\n",
    "\n",
    "# Function to load and extract features from images in a directory\n",
    "def load_and_extract_features(directory, feature_extractor):\n",
    "    features = []\n",
    "    for entry in glob.glob(directory):\n",
    "        img = cv2.imread(entry)\n",
    "        img_features = feature_extractor(img)\n",
    "        features.append(img_features)\n",
    "    return features\n",
    "\n",
    "# Data directories\n",
    "data_directories = [\n",
    "    (\"C:/Capstone/Campus Pictures/Aiken/*\", \"Aiken\"),\n",
    "    (\"C:/Capstone/Campus Pictures/Campus Map/*\", \"Campus Map\"),\n",
    "    (\"C:/Capstone/Campus Pictures/CCM/*\", \"CCM\"),\n",
    "    (\"C:/Capstone/Campus Pictures/Durick Hall/*\", \"Durick Hall\"),\n",
    "    (\"C:/Capstone/Campus Pictures/EATS/*\", \"EATS\"),\n",
    "    (\"C:/Capstone/Campus Pictures/Finney Quad/*\", \"Finney Quad\"),\n",
    "    (\"C:/Capstone/Campus Pictures/Foster/*\", \"Foster\"),\n",
    "    (\"C:/Capstone/Campus Pictures/Freeman Hall/*\", \"Freeman Hall\"),\n",
    "    (\"C:/Capstone/Campus Pictures/Garden House/*\", \"Garden House\"),\n",
    "    (\"C:/Capstone/Campus Pictures/Hauke Courtyard/*\", \"Hauke Courtyard\"),\n",
    "    (\"C:/Capstone/Campus Pictures/Health Center/*\", \"Health Center\"),\n",
    "    (\"C:/Capstone/Campus Pictures/IDX/*\", \"IDX\"),\n",
    "    (\"C:/Capstone/Campus Pictures/Joyce Hall/*\", \"Joyce Hall\"),\n",
    "    (\"C:/Capstone/Campus Pictures/Juniper Bike/*\", \"Juniper Bike\"),\n",
    "    (\"C:/Capstone/Campus Pictures/Metz Studio Barn/*\", \"Metz Studio Barn\"),\n",
    "    (\"C:/Capstone/Campus Pictures/Miller Center/*\", \"Miller Center\"),\n",
    "    (\"C:/Capstone/Campus Pictures/Perry Hall/*\", \"Perry Hall\"),\n",
    "    (\"C:/Capstone/Campus Pictures/Rowell Annex/*\", \"Rowell Annex\"),\n",
    "    (\"C:/Capstone/Campus Pictures/Samuel De Champlain/*\", \"Samuel De Champlain\"),\n",
    "    (\"C:/Capstone/Campus Pictures/SD Ireland/*\", \"SD Ireland\"),\n",
    "    (\"C:/Capstone/Campus Pictures/Skiff Hall/*\", \"Skiff Hall\"),\n",
    "    (\"C:/Capstone/Campus Pictures/West Hall/*\", \"West Hall\"),\n",
    "    (\"C:/Capstone/Campus Pictures/Wick Hall/*\", \"Wick Hall\")\n",
    "]\n",
    "\n",
    "# Load and extract features\n",
    "X_features = []\n",
    "y_labels = []\n",
    "for directory, label in data_directories:\n",
    "    features = load_and_extract_features(directory, extract_hog_features)  # Change to extract_daisy_features for DAISY\n",
    "    X_features.extend(features)\n",
    "    y_labels.extend([label] * len(features))\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(X_features)\n",
    "y = np.array(y_labels)\n",
    "\n",
    "# Shuffle the data\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels for the testing data\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00d502d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validated Accuracy: 0.8216149068322981\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Function for data augmentation\n",
    "def augment_data(images):\n",
    "    augmented_images = []\n",
    "    for img in images:\n",
    "        # Apply transformations to the image (e.g., rotation, flipping, scaling)\n",
    "        augmented_img = img  # Placeholder for transformation code\n",
    "        augmented_images.append(augmented_img)\n",
    "    return augmented_images\n",
    "\n",
    "# Augment data\n",
    "X_train_augmented = augment_data(X_train)\n",
    "y_train_augmented = np.tile(y_train,  # Keep the same labels for augmented data\n",
    "                            len(X_train_augmented) // len(X_train))\n",
    "\n",
    "# Combine original and augmented data\n",
    "X_combined = np.concatenate((X_train, X_train_augmented))\n",
    "y_combined = np.concatenate((y_train, y_train_augmented))\n",
    "\n",
    "# Perform cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "for train_index, test_index in kf.split(X_combined):\n",
    "    X_train_fold, X_test_fold = X_combined[train_index], X_combined[test_index]\n",
    "    y_train_fold, y_test_fold = y_combined[train_index], y_combined[test_index]\n",
    "    \n",
    "    # Train Random Forest classifier\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_classifier.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Predict labels for the testing data\n",
    "    y_pred_fold = rf_classifier.predict(X_test_fold)\n",
    "    \n",
    "    # Calculate accuracy for this fold\n",
    "    accuracy_fold = accuracy_score(y_test_fold, y_pred_fold)\n",
    "    accuracies.append(accuracy_fold)\n",
    "\n",
    "# Calculate mean accuracy across folds\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "print(\"Mean Cross-Validated Accuracy:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78ea200d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luizc\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luizc\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luizc\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luizc\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validated Accuracy: 0.2799154334038055\n",
      "Mean Cross-Validated Precision: 0.18988859297782573\n",
      "Mean Cross-Validated Recall: 0.2799154334038055\n",
      "Mean Cross-Validated F1-score: 0.2015178485500293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luizc\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\luizc\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Initialize lists to store evaluation metrics for each fold\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "# Perform cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    X_train_fold, X_test_fold = X[train_index], X[test_index]\n",
    "    y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "    \n",
    "    # Augment data for this fold\n",
    "    X_train_fold_augmented = augment_data(X_train_fold)\n",
    "    y_train_fold_augmented = np.tile(y_train_fold, len(X_train_fold_augmented) // len(X_train_fold))\n",
    "    \n",
    "    # Combine original and augmented data\n",
    "    X_train_combined = np.concatenate((X_train_fold, X_train_fold_augmented))\n",
    "    y_train_combined = np.concatenate((y_train_fold, y_train_fold_augmented))\n",
    "    \n",
    "    # Train Random Forest classifier\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_classifier.fit(X_train_combined, y_train_combined)\n",
    "    \n",
    "    # Predict labels for the testing data\n",
    "    y_pred_fold = rf_classifier.predict(X_test_fold)\n",
    "    \n",
    "    # Calculate evaluation metrics for this fold\n",
    "    accuracy_fold = accuracy_score(y_test_fold, y_pred_fold)\n",
    "    precision_fold = precision_score(y_test_fold, y_pred_fold, average='weighted')\n",
    "    recall_fold = recall_score(y_test_fold, y_pred_fold, average='weighted')\n",
    "    f1_fold = f1_score(y_test_fold, y_pred_fold, average='weighted')\n",
    "    \n",
    "    # Append scores to lists\n",
    "    accuracy_scores.append(accuracy_fold)\n",
    "    precision_scores.append(precision_fold)\n",
    "    recall_scores.append(recall_fold)\n",
    "    f1_scores.append(f1_fold)\n",
    "\n",
    "# Calculate mean scores across folds\n",
    "mean_accuracy = np.mean(accuracy_scores)\n",
    "mean_precision = np.mean(precision_scores)\n",
    "mean_recall = np.mean(recall_scores)\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "\n",
    "# Print the mean scores\n",
    "print(\"Mean Cross-Validated Accuracy:\", mean_accuracy)\n",
    "print(\"Mean Cross-Validated Precision:\", mean_precision)\n",
    "print(\"Mean Cross-Validated Recall:\", mean_recall)\n",
    "print(\"Mean Cross-Validated F1-score:\", mean_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "925dd0eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: Aiken.jpg, Predicted Label: Skiff Hall\n",
      "Image: CCM.jpg, Predicted Label: Skiff Hall\n",
      "Image: Joyce.jpg, Predicted Label: Skiff Hall\n",
      "Image: perry.jpg, Predicted Label: Skiff Hall\n",
      "Image: SD IREland.jpg, Predicted Label: Skiff Hall\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Function to load and preprocess images\n",
    "def load_and_preprocess_images_from_directory(directory):\n",
    "    images = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            img_path = os.path.join(directory, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            img_features = extract_hog_features(img)\n",
    "            images.append((filename, img_features))\n",
    "    return images\n",
    "\n",
    "# Directory containing the downloaded images\n",
    "test_images_directory = \"C:/Users/luizc/Capstone/test_images/\"\n",
    "\n",
    "# Load and preprocess test images\n",
    "test_images = load_and_preprocess_images_from_directory(test_images_directory)\n",
    "\n",
    "# Predict labels for the test images\n",
    "predicted_labels = []\n",
    "for filename, img_features in test_images:\n",
    "    predicted_label = rf_classifier.predict([img_features])[0]\n",
    "    predicted_labels.append((filename, predicted_label))\n",
    "\n",
    "# Write out the predicted labels for each image\n",
    "for filename, predicted_label in predicted_labels:\n",
    "    print(f\"Image: {filename}, Predicted Label: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417585c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
